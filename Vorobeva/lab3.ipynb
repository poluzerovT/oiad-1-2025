{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1ab589",
   "metadata": {},
   "source": [
    "# ОИАД. Лабораторная работа №3\n",
    "\n",
    "**Датасет:** `insurance.csv` (формат: age,sex,bmi,children,smoker,region,charges`)\n",
    "\n",
    "**Цель работы:** подготовка данных, реализация многомерной линейной регрессии аналитически и численно (градиентный спуск), добавление регуляризации (Ridge), и сравнение моделей по MSE на тесте.\n",
    "\n",
    "Файл содержит подробные комментарии и блоки кода — вы можете запускать ячейки последовательно в Jupyter Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0005388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 0: Импорты и загрузка данных\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Попробуйте заменить путь на ваш local 'insurance.csv' при необходимости\n",
    "csv_path = 'insurance.csv'\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    # Если файла нет, создадим маленькую демонстрационную таблицу (пользуйтесь своим файлом в реальной работе)\n",
    "    data = '''age,sex,bmi,children,smoker,region,charges\n",
    "19,female,27.9,0,yes,southwest,16884.924\n",
    "18,male,33.77,1,no,southeast,1725.5523\n",
    "28,male,33,3,no,southeast,4449.462\n",
    "33,male,22.705,0,no,northwest,21984.47061\n",
    "32,male,28.88,0,no,northwest,3866.8552\n",
    "31,female,25.74,0,no,southeast,3756.6216\n",
    "46,female,33.44,1,no,southeast,8240.5896\n",
    "37,female,27.74,3,no,northwest,7281.5056\n",
    "37,male,29.83,2,no,northeast,6406.4107\n",
    "60,female,25.84,0,no,northwest,28923.13692\n",
    "25,male,26.22,0,no,northeast,2721.3208\n",
    "62,female,26.29,0,yes,southeast,27808.7251\n",
    "23,male,34.4,0,no,southwest,1826.843\n",
    "56,female,39.82,0,no,southeast,11090.7178\n",
    "27,male,42.13,0,yes,southeast,39611.7577\n",
    "19,male,24.6,1,no,southwest,1837.237\n",
    "52,female,30.78,1,no,northeast,10797.3362\n",
    "23,male,23.845,0,no,northeast,2395.17155\n",
    "56,male,40.3,0,no,southwest,10602.385\n",
    "30,male,35.3,0,yes,southwest,36837.467\n",
    "60,female,36.005,0,no,northeast,13228.84695\n",
    "30,female,32.4,1,no,southwest,4149.736\n",
    "18,male,34.1,0,no,southeast,1137.011\n",
    "34,female,31.92,1,yes,northeast,37701.8768\n",
    "37,male,28.025,2,no,northwest,6203.90175\n",
    "59,female,27.72,3,no,southeast,14001.1338\n",
    "'''\n",
    "    import io\n",
    "    df = pd.read_csv(io.StringIO(data))\n",
    "\n",
    "print('Загружено строк:', len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07117fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Подготовка данных\n",
    "# 1.1 Проверка на пропуски и базовая статистика\n",
    "print('Пропуски по столбцам:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print('\\nТипы столбцов:')\n",
    "print(df.dtypes)\n",
    "\n",
    "print('\\nБазовые описательные статистики (числовые признаки):')\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dda72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Поиск выбросов (IQR и Z-score)\n",
    "numeric_cols = ['age','bmi','children','charges']\n",
    "\n",
    "# IQR метод\n",
    "outliers_iqr = {}\n",
    "for c in numeric_cols:\n",
    "    Q1 = df[c].quantile(0.25)\n",
    "    Q3 = df[c].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    low = Q1 - 1.5 * IQR\n",
    "    high = Q3 + 1.5 * IQR\n",
    "    mask = (df[c] < low) | (df[c] > high)\n",
    "    outliers_iqr[c] = df[mask]\n",
    "    print(f\"{c}: {mask.sum()} выбросов по IQR (пределы {low:.2f}..{high:.2f})\")\n",
    "\n",
    "# Z-score (для информации)\n",
    "from scipy import stats\n",
    "z = np.abs(stats.zscore(df[numeric_cols]))\n",
    "z_outliers = (z > 3).any(axis=1)\n",
    "print('\\nПо Z-score (>3):', z_outliers.sum(), 'строк')\n",
    "\n",
    "# Покажем примеры выбросов (если есть)\n",
    "for c,rows in outliers_iqr.items():\n",
    "    if len(rows)>0:\n",
    "        print('\\nПримеры выбросов по', c)\n",
    "        print(rows[[c,'sex','smoker','charges']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579033cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Приведение категориальных признаков к числовым (one-hot и бинарные)\n",
    "# sex -> binary, smoker -> binary, region -> one-hot\n",
    "\n",
    "df2 = df.copy()\n",
    "df2['sex'] = (df2['sex'] == 'male').astype(int)\n",
    "df2['smoker'] = (df2['smoker'] == 'yes').astype(int)\n",
    "# region one-hot\n",
    "df2 = pd.get_dummies(df2, columns=['region'], drop_first=True)\n",
    "\n",
    "print('Колонки после кодирования:')\n",
    "print(df2.columns.tolist())\n",
    "\n",
    "# 1.4 Парные корреляции\n",
    "corr = df2.corr()\n",
    "print('\\nМатрица корреляций (фрагмент):')\n",
    "print(corr[['charges']].sort_values(by='charges', ascending=False))\n",
    "\n",
    "# Покажем heatmap (matplotlib)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(corr, interpolation='nearest')\n",
    "plt.title('Корреляционная матрица (все признаки)')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44bb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Многомерная линейная регрессия\n",
    "# Подготовка X, y\n",
    "features = [c for c in df2.columns if c != 'charges']\n",
    "X = df2[features].values.astype(float)\n",
    "y = df2['charges'].values.reshape(-1,1)\n",
    "\n",
    "# Добавим столбец единиц для свободного члена\n",
    "def add_bias(X):\n",
    "    return np.hstack([np.ones((X.shape[0],1)), X])\n",
    "\n",
    "# Разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_b = add_bias(X_train)\n",
    "X_test_b = add_bias(X_test)\n",
    "\n",
    "# 2.1 Аналитическое решение (обычное МНК)\n",
    "def normal_equation(X_b, y):\n",
    "    # w = (X^T X)^{-1} X^T y\n",
    "    XtX = X_b.T.dot(X_b)\n",
    "    try:\n",
    "        inv = np.linalg.inv(XtX)\n",
    "    except np.linalg.LinAlgError:\n",
    "        inv = np.linalg.pinv(XtX)\n",
    "    w = inv.dot(X_b.T).dot(y)\n",
    "    return w\n",
    "\n",
    "w_analytical = normal_equation(X_train_b, y_train)\n",
    "print('Веса (аналитически):')\n",
    "print(w_analytical.flatten())\n",
    "\n",
    "# 2.2 Градиентный спуск (реализация)\n",
    "class LinearGD:\n",
    "    def __init__(self, lr=0.01, n_iter=10000, tol=1e-6, verbose=False):\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "    def fit(self, X_b, y):\n",
    "        n, m = X_b.shape\n",
    "        self.w = np.zeros((m,1))\n",
    "        prev_loss = np.inf\n",
    "        for i in range(self.n_iter):\n",
    "            preds = X_b.dot(self.w)\n",
    "            error = preds - y\n",
    "            grad = (2/n) * X_b.T.dot(error)\n",
    "            self.w -= self.lr * grad\n",
    "            loss = np.mean(error**2)\n",
    "            if self.verbose and i% (self.n_iter//5 if self.n_iter>=5 else 1)==0:\n",
    "                print(f'iter {i}, loss={loss:.6f}')\n",
    "            if abs(prev_loss - loss) < self.tol:\n",
    "                break\n",
    "            prev_loss = loss\n",
    "        return self\n",
    "    def predict(self, X_b):\n",
    "        return X_b.dot(self.w)\n",
    "\n",
    "# Для стабильности градиентного спуска масштабируем признаки (не включая bias)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_b_s = add_bias(X_train_scaled)\n",
    "X_test_b_s = add_bias(X_test_scaled)\n",
    "\n",
    "gd = LinearGD(lr=0.1, n_iter=20000, tol=1e-8, verbose=False)\n",
    "_ = gd.fit(X_train_b_s, y_train)\n",
    "print('Веса (градиентный спуск, на стандартизованных признаках):')\n",
    "print(gd.w.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeedb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Добавление регуляризации (Ridge)\n",
    "# 3.1 Аналитическое решение для Ridge: w = (X^T X + lambda * I)^-1 X^T y\n",
    "\n",
    "def ridge_normal_equation(X_b, y, lam):\n",
    "    m = X_b.shape[1]\n",
    "    XtX = X_b.T.dot(X_b)\n",
    "    # не штрафуем свободный член: ставим 0 в верхнем левом элементе\n",
    "    L = lam * np.eye(m)\n",
    "    L[0,0] = 0\n",
    "    try:\n",
    "        inv = np.linalg.inv(XtX + L)\n",
    "    except np.linalg.LinAlgError:\n",
    "        inv = np.linalg.pinv(XtX + L)\n",
    "    w = inv.dot(X_b.T).dot(y)\n",
    "    return w\n",
    "\n",
    "# Подберём lambda по простому сеточному поиску на валидации (train split -> train/val)\n",
    "X_sub_train, X_val, y_sub_train, y_val = train_test_split(X_train_b, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "lambdas = [0.0, 0.01, 0.1, 1, 10, 100]\n",
    "best_l = None\n",
    "best_mse = np.inf\n",
    "for lam in lambdas:\n",
    "    w_r = ridge_normal_equation(X_sub_train, y_sub_train, lam)\n",
    "    preds = X_val.dot(w_r)\n",
    "    mse = mean_squared_error(y_val, preds)\n",
    "    print(f'lambda={lam}: val MSE={mse:.4f}')\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_l = lam\n",
    "\n",
    "print('\\nЛучший lambda по простому поиску:', best_l)\n",
    "w_ridge_analytical = ridge_normal_equation(X_train_b, y_train, best_l)\n",
    "print('Веса Ridge (аналитически):')\n",
    "print(w_ridge_analytical.flatten())\n",
    "\n",
    "# 3.2 Градиентный спуск с регуляризацией (L2)\n",
    "class RidgeGD(LinearGD):\n",
    "    def __init__(self, lr=0.01, n_iter=10000, lam=1.0, tol=1e-6, verbose=False):\n",
    "        super().__init__(lr=lr, n_iter=n_iter, tol=tol, verbose=verbose)\n",
    "        self.lam = lam\n",
    "    def fit(self, X_b, y):\n",
    "        n, m = X_b.shape\n",
    "        self.w = np.zeros((m,1))\n",
    "        prev_loss = np.inf\n",
    "        for i in range(self.n_iter):\n",
    "            preds = X_b.dot(self.w)\n",
    "            error = preds - y\n",
    "            grad = (2/n) * (X_b.T.dot(error) + self.lam * np.vstack([ [0.0], self.w[1:]] ))\n",
    "            self.w -= self.lr * grad\n",
    "            loss = np.mean(error**2) + self.lam * (self.w[1:]**2).sum()\n",
    "            if self.verbose and i% (self.n_iter//5 if self.n_iter>=5 else 1)==0:\n",
    "                print(f'iter {i}, loss={loss:.6f}')\n",
    "            if abs(prev_loss - loss) < self.tol:\n",
    "                break\n",
    "            prev_loss = loss\n",
    "        return self\n",
    "\n",
    "# Обучим RidgeGD на стандартизованных данных\n",
    "rgd = RidgeGD(lr=0.05, n_iter=20000, lam=best_l, tol=1e-8, verbose=False)\n",
    "rgd.fit(X_train_b_s, y_train)\n",
    "print('Веса Ridge GD (стандартизованные признаки):')\n",
    "print(rgd.w.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Оценка обобщающей способности\n",
    "# 4.1 Бейзлайн: константный предсказатель (среднее по train)\n",
    "mean_pred = np.mean(y_train)\n",
    "mse_baseline = mean_squared_error(y_test, np.full_like(y_test, mean_pred))\n",
    "print('Baseline (mean) MSE:', mse_baseline)\n",
    "\n",
    "# 4.2 Аналитическая линейная модель\n",
    "pred_analytical = X_test_b.dot(w_analytical)\n",
    "mse_analytical = mean_squared_error(y_test, pred_analytical)\n",
    "print('Analytical OLS MSE:', mse_analytical)\n",
    "\n",
    "# 4.3 GD (на стандартизованных)\n",
    "pred_gd = X_test_b_s.dot(gd.w)\n",
    "mse_gd = mean_squared_error(y_test, pred_gd)\n",
    "print('Gradient Descent MSE:', mse_gd)\n",
    "\n",
    "# 4.4 Ridge analytical\n",
    "pred_ridge_a = X_test_b.dot(w_ridge_analytical)\n",
    "mse_ridge_a = mean_squared_error(y_test, pred_ridge_a)\n",
    "print('Ridge Analytic MSE (lambda={}):'.format(best_l), mse_ridge_a)\n",
    "\n",
    "# 4.5 Ridge GD (стандартизованные)\n",
    "pred_ridge_gd = X_test_b_s.dot(rgd.w)\n",
    "mse_ridge_gd = mean_squared_error(y_test, pred_ridge_gd)\n",
    "print('Ridge GD MSE:', mse_ridge_gd)\n",
    "\n",
    "# Сводная таблица\n",
    "results = pd.DataFrame({\n",
    "    'model': ['baseline_mean','ols_analytic','gd','ridge_analytic','ridge_gd'],\n",
    "    'mse': [mse_baseline, mse_analytical, mse_gd, mse_ridge_a, mse_ridge_gd]\n",
    "}).sort_values('mse')\n",
    "\n",
    "print('\\nСравнение моделей (по MSE на тесте):')\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cedaef0",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "- В ноутбуке реализованы: проверка данных, кодирование категориальных признаков, проверка выбросов (IQR, Z-score), корреляции, аналитическое решение линейной регрессии (нормальное уравнение), градиентный спуск, добавление L2-регуляризации (Ridge) аналитически и численно, и сравнение моделей по MSE.\n",
    "\n",
    "- В реальной работе рекомендуется: масштабировать признаки перед обучением градиентных методов, проводить кросс-валидацию для выбора параметра регуляризации, визуализировать остатки и проводить диагностику многоколлинеарности (VIF).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним итоговый ноутбук и веса\n",
    "import numpy as _np\n",
    "weights = {\n",
    "    'w_ols': w_analytical.flatten(),\n",
    "    'w_ridge_analytic': w_ridge_analytical.flatten(),\n",
    "}\n",
    "_np.savez('lab3_weights.npz', **weights)\n",
    "\n",
    "import nbformat as _nbf\n",
    "out_path = '/mnt/data/insurance_lab3.ipynb'\n",
    "with open(out_path, 'w', encoding='utf-8') as f:\n",
    "    _nbf.write(nb, f)\n",
    "\n",
    "print('Сохранён ноутбук:', out_path)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
